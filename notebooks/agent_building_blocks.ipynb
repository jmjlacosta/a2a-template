{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2A Agent Building Blocks\n",
    "\n",
    "This notebook contains all the necessary building blocks to create an A2A-compliant agent.\n",
    "\n",
    "## How to Use This Notebook\n",
    "\n",
    "1. **Copy the code cells** you need for your agent\n",
    "2. **Modify** the agent name, description, and business logic\n",
    "3. **Duplicate tool cells** if you need multiple tools\n",
    "4. **Combine all cells** at the end to create your complete agent\n",
    "\n",
    "## Key Concepts (A2A Specification)\n",
    "\n",
    "- **Messages** (§6.4): Requests sent TO agents (role: user/agent)\n",
    "- **Artifacts** (§6.7): Outputs generated BY agents (artifactId + parts)\n",
    "- **Parts** (§6.5): Content units - TextPart or DataPart with 'kind' discriminator\n",
    "- **Tasks** (§6.1): Execution context containing history (Messages) and artifacts (outputs)\n",
    "\n",
    "The flow: Orchestrator sends **Message** → Agent processes → Returns **Artifact**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Essential imports for any A2A agent. The base class handles all protocol compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Your Agent Name - Brief description of what your agent does.\n",
    "Fully A2A-compliant agent following specification v0.3.0.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union, Dict, Any\n",
    "\n",
    "# Add parent directories to path for imports (if running as script)\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent))\n",
    "\n",
    "# Core A2A imports\n",
    "from base import A2AAgent\n",
    "from a2a.types import AgentSkill\n",
    "from utils.logging import get_logger\n",
    "\n",
    "# Optional: For LLM integration (if not using tools)\n",
    "from utils.llm_utils import generate_text\n",
    "\n",
    "# Set up logging\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Base Agent Class\n",
    "\n",
    "Every agent must extend `A2AAgent` and implement the required methods.\n",
    "The base class handles all A2A protocol details - you just implement business logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAgent(A2AAgent):\n",
    "    \"\"\"\n",
    "    Your agent implementation.\n",
    "    \n",
    "    The A2AAgent base class handles:\n",
    "    - Task lifecycle management (§6.1)\n",
    "    - Message extraction and validation (§6.4)\n",
    "    - Artifact generation (§6.7)\n",
    "    - Error handling and status updates\n",
    "    - Protocol compliance\n",
    "    \n",
    "    You only need to implement:\n",
    "    - Metadata methods (name, description)\n",
    "    - Business logic (process_message)\n",
    "    - Optional: tools, skills, system instruction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the agent.\"\"\"\n",
    "        super().__init__()\n",
    "        # Add any agent-specific initialization here\n",
    "        self.config = {\n",
    "            \"max_retries\": 3,\n",
    "            \"timeout\": 30\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Required Metadata Methods\n",
    "\n",
    "These methods define your agent's identity and are used in the AgentCard (§5.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # REQUIRED: Agent name for discovery\n",
    "    def get_agent_name(self) -> str:\n",
    "        \"\"\"Return the agent's name (used in AgentCard).\"\"\"\n",
    "        return \"My Custom Agent\"\n",
    "    \n",
    "    # REQUIRED: Agent description for users/orchestrators\n",
    "    def get_agent_description(self) -> str:\n",
    "        \"\"\"Return detailed description of agent capabilities.\"\"\"\n",
    "        return (\n",
    "            \"An agent that processes data and returns insights. \"\n",
    "            \"Supports both text and structured data input. \"\n",
    "            \"Returns analyzed results as text or JSON.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optional Metadata Methods\n",
    "\n",
    "Enhance your agent with version, skills, and streaming support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # OPTIONAL: Version tracking\n",
    "    def get_agent_version(self) -> str:\n",
    "        \"\"\"Return agent version.\"\"\"\n",
    "        return \"1.0.0\"\n",
    "    \n",
    "    # OPTIONAL: Streaming support declaration\n",
    "    def supports_streaming(self) -> bool:\n",
    "        \"\"\"Return True if agent supports streaming responses.\"\"\"\n",
    "        return False  # Set to True if you implement streaming\n",
    "    \n",
    "    # OPTIONAL: Declare agent capabilities/skills (§5.5.4)\n",
    "    def get_agent_skills(self) -> List[AgentSkill]:\n",
    "        \"\"\"Declare specific capabilities for the AgentCard.\"\"\"\n",
    "        return [\n",
    "            AgentSkill(\n",
    "                id=\"data_analysis\",\n",
    "                name=\"Data Analysis\",\n",
    "                description=\"Analyze structured data and provide insights\",\n",
    "                tags=[\"analysis\", \"data\", \"insights\"],\n",
    "                examples=[\n",
    "                    \"Analyze this dataset\",\n",
    "                    \"What patterns do you see?\",\n",
    "                    \"Summarize the key findings\"\n",
    "                ],\n",
    "                inputModes=[\"text/plain\", \"application/json\"],\n",
    "                outputModes=[\"text/plain\", \"application/json\"]\n",
    "            ),\n",
    "            # Add more skills as needed\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Core Processing Logic\n",
    "\n",
    "The `process_message` method is where your agent's business logic lives.\n",
    "It receives extracted message content and returns output for an Artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # REQUIRED: Main processing logic\n",
    "    async def process_message(self, message: str) -> Union[str, Dict, List]:\n",
    "        \"\"\"\n",
    "        Process the incoming message and return output.\n",
    "        \n",
    "        The base class has already:\n",
    "        - Extracted message content from all Parts (§6.5)\n",
    "        - Concatenated TextParts and serialized DataParts\n",
    "        - Created the Task and updated status to 'working'\n",
    "        \n",
    "        Args:\n",
    "            message: Extracted content (could be text or JSON string)\n",
    "            \n",
    "        Returns:\n",
    "            - str: Will be wrapped in TextPart within an Artifact\n",
    "            - dict/list: Will be wrapped in DataPart within an Artifact\n",
    "            \n",
    "        The return value is automatically wrapped in an Artifact (§6.7)\n",
    "        by the base class - agents produce outputs, not conversations.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Processing message of length {len(message)}\")\n",
    "        \n",
    "        # Try to detect if message is structured data\n",
    "        try:\n",
    "            data = json.loads(message)\n",
    "            # Process structured data\n",
    "            result = await self._process_data(data)\n",
    "            return result  # Return dict/list for DataPart\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            # Process as text\n",
    "            result = await self._process_text(message)\n",
    "            return result  # Return string for TextPart\n",
    "    \n",
    "    # Helper methods for processing\n",
    "    async def _process_text(self, text: str) -> str:\n",
    "        \"\"\"Process text input and return text output.\"\"\"\n",
    "        # Your text processing logic here\n",
    "        analysis = f\"Processed {len(text.split())} words\"\n",
    "        return f\"Analysis complete: {analysis}\"\n",
    "    \n",
    "    async def _process_data(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Process structured data and return structured output.\"\"\"\n",
    "        # Your data processing logic here\n",
    "        return {\n",
    "            \"status\": \"analyzed\",\n",
    "            \"input_keys\": list(data.keys()),\n",
    "            \"record_count\": len(data.get(\"records\", [])),\n",
    "            \"summary\": \"Data processed successfully\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Using Pydantic for Structured Outputs\n\nWhen your agent needs to return structured data, Pydantic models provide validation and clear contracts. \nEach agent handles its own data formatting - no magic in base.py.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adding LLM Integration\n",
    "\n",
    "For agents that need LLM capabilities without tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # OPTIONAL: Custom system instruction for LLM\n",
    "    def get_system_instruction(self) -> str:\n",
    "        \"\"\"Provide system instruction for LLM-based processing.\"\"\"\n",
    "        return (\n",
    "            \"You are a specialized data analysis agent. \"\n",
    "            \"Analyze the provided data and return clear, actionable insights. \"\n",
    "            \"Be concise but thorough in your analysis.\"\n",
    "        )\n",
    "    \n",
    "    # Example: Using LLM in process_message\n",
    "    async def process_message_with_llm(self, message: str) -> str:\n",
    "        \"\"\"Alternative process_message using LLM.\"\"\"\n",
    "        # Use the auto-detecting LLM utility\n",
    "        response = await generate_text(\n",
    "            prompt=f\"Analyze this: {message}\",\n",
    "            system_instruction=self.get_system_instruction(),\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        return response or \"Unable to generate analysis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Adding Tools (Google ADK FunctionTool)\n",
    "\n",
    "Tools allow the LLM to perform specific actions. Each tool is a function that the LLM can call.\n",
    "**Copy this cell multiple times** if you need multiple tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool definition (create one cell per tool)\n",
    "from google.adk.tools import FunctionTool\n",
    "\n",
    "def analyze_metrics(\n",
    "    data: Dict[str, Any],\n",
    "    metric_type: str = \"summary\",\n",
    "    include_trends: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Analyze metrics from provided data.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary containing metric data\n",
    "        metric_type: Type of analysis (summary, detailed, comparison)\n",
    "        include_trends: Whether to include trend analysis\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with analysis results\n",
    "    \"\"\"\n",
    "    # Tool implementation\n",
    "    results = {\n",
    "        \"type\": metric_type,\n",
    "        \"metrics_analyzed\": len(data),\n",
    "        \"summary\": f\"Analyzed {len(data)} metrics\"\n",
    "    }\n",
    "    \n",
    "    if include_trends:\n",
    "        results[\"trends\"] = \"Upward trend detected\"\n",
    "    \n",
    "    return json.dumps(results, indent=2)\n",
    "\n",
    "# Create another tool (duplicate this pattern)\n",
    "def query_database(\n",
    "    query: str,\n",
    "    limit: int = 10\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Execute a database query (simulated).\n",
    "    \n",
    "    Args:\n",
    "        query: SQL-like query string\n",
    "        limit: Maximum results to return\n",
    "        \n",
    "    Returns:\n",
    "        Query results as JSON string\n",
    "    \"\"\"\n",
    "    # Simulated database query\n",
    "    return json.dumps({\n",
    "        \"query\": query,\n",
    "        \"results\": [{\"id\": i, \"value\": f\"row_{i}\"} for i in range(min(limit, 3))],\n",
    "        \"count\": min(limit, 3)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Add tools to your agent class\n",
    "    def get_tools(self) -> List[FunctionTool]:\n",
    "        \"\"\"\n",
    "        Return tools available to this agent.\n",
    "        The LLM will automatically use these tools when appropriate.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            FunctionTool(analyze_metrics),\n",
    "            FunctionTool(query_database),\n",
    "            # Add more FunctionTool instances for each tool\n",
    "        ]\n",
    "    \n",
    "    # When tools are provided, process_message won't be called directly\n",
    "    # The base class handles tool execution via the LLM\n",
    "    async def process_message(self, message: str) -> str:\n",
    "        \"\"\"This won't be called when tools are provided.\"\"\"\n",
    "        return \"Handled by tool execution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Inter-Agent Communication\n",
    "\n",
    "Agents can call other agents using the unified `call_agent` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    async def process_with_other_agents(self, message: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Example of calling other agents from your agent.\n",
    "        \"\"\"\n",
    "        # Call another agent with text (auto-wrapped in TextPart)\n",
    "        analysis_result = await self.call_agent(\n",
    "            \"http://analyzer-agent:8000\",  # Or use agent name from config\n",
    "            f\"Analyze this data: {message}\"\n",
    "        )\n",
    "        \n",
    "        # Call with structured data (auto-wrapped in DataPart)\n",
    "        validation_result = await self.call_agent(\n",
    "            \"http://validator-agent:8000\",\n",
    "            {\n",
    "                \"data\": message,\n",
    "                \"rules\": [\"check_format\", \"verify_completeness\"]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Call with pre-formatted Message (multiple parts)\n",
    "        complex_result = await self.call_agent(\n",
    "            \"http://processor-agent:8000\",\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [\n",
    "                    {\"kind\": \"text\", \"text\": \"Process this:\"},\n",
    "                    {\"kind\": \"data\", \"data\": {\"input\": message}}\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Combine results (all are Artifacts with outputs)\n",
    "        return {\n",
    "            \"analysis\": analysis_result,\n",
    "            \"validation\": validation_result,\n",
    "            \"processing\": complex_result\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Error Handling\n",
    "\n",
    "Proper error handling ensures robust agent operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    async def process_message_with_errors(self, message: str) -> Union[str, Dict]:\n",
    "        \"\"\"\n",
    "        Example with comprehensive error handling.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate input\n",
    "            if not message or len(message) < 10:\n",
    "                return {\"error\": \"Input too short\", \"min_length\": 10}\n",
    "            \n",
    "            # Process with timeout\n",
    "            import asyncio\n",
    "            try:\n",
    "                result = await asyncio.wait_for(\n",
    "                    self._heavy_processing(message),\n",
    "                    timeout=30.0\n",
    "                )\n",
    "                return result\n",
    "            except asyncio.TimeoutError:\n",
    "                logger.error(\"Processing timeout\")\n",
    "                return {\"error\": \"Processing timeout\", \"partial_result\": None}\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(f\"JSON parsing error: {e}\")\n",
    "            return {\"error\": \"Invalid JSON format\", \"details\": str(e)}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error: {e}\")\n",
    "            # Return error as structured data\n",
    "            return {\n",
    "                \"error\": \"Processing failed\",\n",
    "                \"type\": type(e).__name__,\n",
    "                \"message\": str(e)\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Complete Agent Example\n",
    "\n",
    "Here's how all the pieces come together into a complete agent file (`agent.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Complete A2A Agent Example\n",
    "Copy this entire cell to create your agent.py file.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union, Dict, Any\n",
    "\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent))\n",
    "\n",
    "from base import A2AAgent\n",
    "from a2a.types import AgentSkill\n",
    "from utils.logging import get_logger\n",
    "from google.adk.tools import FunctionTool\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "# Define tools (if using)\n",
    "def process_data(data: Dict[str, Any], operation: str = \"analyze\") -> str:\n",
    "    \"\"\"Process data with specified operation.\"\"\"\n",
    "    result = {\n",
    "        \"operation\": operation,\n",
    "        \"input_size\": len(str(data)),\n",
    "        \"status\": \"completed\"\n",
    "    }\n",
    "    return json.dumps(result)\n",
    "\n",
    "\n",
    "class MyCompleteAgent(A2AAgent):\n",
    "    \"\"\"Complete A2A-compliant agent with all features.\"\"\"\n",
    "    \n",
    "    def get_agent_name(self) -> str:\n",
    "        return \"Complete Example Agent\"\n",
    "    \n",
    "    def get_agent_description(self) -> str:\n",
    "        return (\n",
    "            \"A complete example agent demonstrating all A2A features. \"\n",
    "            \"Processes text and data, uses tools, and can call other agents.\"\n",
    "        )\n",
    "    \n",
    "    def get_agent_version(self) -> str:\n",
    "        return \"1.0.0\"\n",
    "    \n",
    "    def get_system_instruction(self) -> str:\n",
    "        return (\n",
    "            \"You are a helpful agent that processes requests accurately. \"\n",
    "            \"Use the available tools when appropriate. \"\n",
    "            \"Return clear, structured responses.\"\n",
    "        )\n",
    "    \n",
    "    def get_tools(self) -> List[FunctionTool]:\n",
    "        \"\"\"Provide tools for LLM to use.\"\"\"\n",
    "        return [\n",
    "            FunctionTool(process_data),\n",
    "            # Add more tools as needed\n",
    "        ]\n",
    "    \n",
    "    def get_agent_skills(self) -> List[AgentSkill]:\n",
    "        return [\n",
    "            AgentSkill(\n",
    "                id=\"processing\",\n",
    "                name=\"Data Processing\",\n",
    "                description=\"Process and analyze various data formats\",\n",
    "                tags=[\"data\", \"analysis\", \"processing\"],\n",
    "                inputModes=[\"text/plain\", \"application/json\"],\n",
    "                outputModes=[\"application/json\"]\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    async def process_message(self, message: str) -> Union[str, Dict, List]:\n",
    "        \"\"\"\n",
    "        Main processing logic.\n",
    "        Note: This won't be called if tools are provided.\n",
    "        \"\"\"\n",
    "        # Since we have tools, this is just a fallback\n",
    "        return \"Processing handled by tools\"\n",
    "\n",
    "\n",
    "# Module-level instance for import\n",
    "agent = MyCompleteAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Main Entry Point\n",
    "\n",
    "The `main.py` file is almost always the same - it just imports your agent and starts the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "main.py - Entry point for your agent.\n",
    "This file is mostly the same for all agents.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent))\n",
    "\n",
    "import uvicorn\n",
    "from a2a.server.apps import A2AStarletteApplication\n",
    "from a2a.server.request_handlers import DefaultRequestHandler\n",
    "from a2a.server.tasks import InMemoryTaskStore\n",
    "from utils.logging import get_logger, setup_logging\n",
    "\n",
    "# Import YOUR agent here (change this line)\n",
    "from agent import MyCompleteAgent\n",
    "\n",
    "setup_logging()\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "def create_app():\n",
    "    \"\"\"Create the A2A application.\"\"\"\n",
    "    # Instantiate your agent\n",
    "    agent = MyCompleteAgent()\n",
    "    logger.info(f\"Initializing {agent.get_agent_name()} v{agent.get_agent_version()}\")\n",
    "    \n",
    "    # Create A2A components\n",
    "    agent_card = agent.create_agent_card()\n",
    "    task_store = InMemoryTaskStore()\n",
    "    request_handler = DefaultRequestHandler(\n",
    "        agent_executor=agent,\n",
    "        task_store=task_store\n",
    "    )\n",
    "    \n",
    "    # Build Starlette app with A2A endpoints\n",
    "    app = A2AStarletteApplication(\n",
    "        agent_card=agent_card,\n",
    "        http_handler=request_handler\n",
    "    ).build()\n",
    "    \n",
    "    return app, agent\n",
    "\n",
    "app, agent = create_app()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    port = int(os.getenv(\"PORT\", \"8000\"))\n",
    "    host = os.getenv(\"HOST\", \"0.0.0.0\")\n",
    "    \n",
    "    logger.info(f\"Starting {agent.get_agent_name()} on http://{host}:{port}\")\n",
    "    logger.info(f\"Agent Card: http://localhost:{port}/.well-known/agent-card.json\")\n",
    "    logger.info(f\"A2A Endpoint: http://localhost:{port}/a2a/v1/message/sync\")\n",
    "    \n",
    "    uvicorn.run(app, host=host, port=port, log_level=\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Configuration (agents.json)\n",
    "\n",
    "Configure known agents for inter-agent communication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config/agents.json\n",
    "{\n",
    "    \"agents\": {\n",
    "        \"analyzer\": {\n",
    "            \"url\": \"http://analyzer-agent:8000\",\n",
    "            \"description\": \"Data analysis agent\"\n",
    "        },\n",
    "        \"validator\": {\n",
    "            \"url\": \"http://validator-agent:8000\",\n",
    "            \"description\": \"Data validation agent\"\n",
    "        },\n",
    "        \"processor\": {\n",
    "            \"url\": \"http://processor-agent:8000\",\n",
    "            \"description\": \"Data processing agent\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You now have all the building blocks to create an A2A-compliant agent:\n",
    "\n",
    "1. **Copy the cells** you need\n",
    "2. **Modify** names, descriptions, and logic\n",
    "3. **Add tools** by duplicating tool cells\n",
    "4. **Save as `agent.py`** in your agent directory\n",
    "5. **Copy the main.py template** (changing only the import)\n",
    "6. **Run** with `python main.py`\n",
    "\n",
    "Remember the key flow:\n",
    "- Agents receive **Messages** (requests)\n",
    "- Process them (with optional tools)\n",
    "- Return **Artifacts** (outputs)\n",
    "\n",
    "The base class handles all A2A protocol details - you just implement business logic!"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Define your output structure with Pydantic\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import List, Dict, Any\n\nclass AnalysisResult(BaseModel):\n    \"\"\"Define what your agent returns - clear contract for outputs.\"\"\"\n    summary: str = Field(description=\"Brief summary of findings\")\n    confidence: float = Field(ge=0, le=1, description=\"Confidence score between 0 and 1\")\n    findings: List[str] = Field(description=\"List of key findings\")\n    metadata: Dict[str, Any] = Field(default_factory=dict, description=\"Additional metadata\")\n    \n    # You can add examples for documentation\n    model_config = {\n        \"json_schema_extra\": {\n            \"examples\": [\n                {\n                    \"summary\": \"Analysis of medical record\",\n                    \"confidence\": 0.95,\n                    \"findings\": [\"Patient shows improvement\", \"No adverse reactions\"],\n                    \"metadata\": {\"processed_at\": \"2024-01-01\", \"version\": \"1.0\"}\n                }\n            ]\n        }\n    }",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Approach 1: Manual Creation with Validation\n\nWhen you know exactly what data you're returning, create the Pydantic model directly:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "    async def process_message(self, message: str) -> Dict[str, Any]:\n        \"\"\"Process and return structured data manually.\"\"\"\n        \n        # Do your actual processing\n        word_count = len(message.split())\n        has_questions = '?' in message\n        \n        # Create Pydantic model for validation\n        # This ensures your data is correctly structured\n        result = AnalysisResult(\n            summary=f\"Analyzed text with {word_count} words\",\n            confidence=0.95 if word_count > 10 else 0.7,\n            findings=[\n                f\"Word count: {word_count}\",\n                f\"Contains questions: {has_questions}\",\n                \"Analysis complete\"\n            ],\n            metadata={\n                \"agent\": self.get_agent_name(),\n                \"timestamp\": time.time()\n            }\n        )\n        \n        # IMPORTANT: Return as dict for DataPart (A2A requirement)\n        # DataPart.data must be a dictionary, not a Pydantic model\n        return result.model_dump()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Approach 2: LLM-Generated with Validation\n\nWhen using an LLM to generate structured output, provide the schema and validate the response:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "    async def process_message_with_llm(self, message: str) -> Dict[str, Any]:\n        \"\"\"Use LLM to generate structured output matching Pydantic schema.\"\"\"\n        \n        # Get the JSON schema from Pydantic model\n        schema_json = AnalysisResult.model_json_schema()\n        \n        # Create prompt with schema\n        prompt = f\"\"\"\n        Analyze the following text and return a JSON response that exactly matches this schema:\n        \n        Schema:\n        {json.dumps(schema_json, indent=2)}\n        \n        Text to analyze:\n        {message}\n        \n        Return ONLY valid JSON, no additional text.\n        \"\"\"\n        \n        # Use Google ADK via llm_utils (stays within A2A framework)\n        from utils.llm_utils import generate_text\n        \n        llm_response = await generate_text(\n            prompt=prompt,\n            system_instruction=\"You are a JSON generator. Return only valid JSON matching the provided schema.\",\n            temperature=0.1,  # Low temperature for consistent structure\n            max_tokens=500\n        )\n        \n        # Validate LLM output with Pydantic\n        try:\n            # Parse and validate the JSON\n            result = AnalysisResult.model_validate_json(llm_response)\n            \n            # Return as dict for DataPart\n            return result.model_dump()\n            \n        except ValidationError as e:\n            # Handle invalid LLM output\n            logger.error(f\"LLM generated invalid JSON: {e}\")\n            \n            # Return error as structured data\n            return {\n                \"error\": \"LLM generated invalid structure\",\n                \"validation_errors\": e.errors(),\n                \"raw_response\": llm_response[:200]  # First 200 chars for debugging\n            }\n        except json.JSONDecodeError as e:\n            # Handle non-JSON response\n            logger.error(f\"LLM didn't return JSON: {e}\")\n            return {\n                \"error\": \"LLM response was not valid JSON\",\n                \"details\": str(e),\n                \"raw_response\": llm_response[:200]\n            }",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Why We Use `.model_dump()`\n\nThe A2A specification requires that DataPart contains a dictionary (§6.5.3):\n\n```typescript\n// From A2A Specification\nexport interface DataPart extends PartBase {\n    readonly kind: \"data\";\n    data: { [key: string]: any };  // <-- Must be a dictionary/object\n}\n```\n\nSince:\n- Pydantic models are Python class instances, not dictionaries\n- DataPart.data requires a dict type\n- `.model_dump()` converts the Pydantic model to a dict\n\nThis is explicit and clear - each agent handles its own data formatting, no hidden magic!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 13. Common LLM Integration Pitfalls 🚨\n\nHere are critical issues we discovered during debugging that can save you hours:\n\n### F-String Formatting with JSON Examples\n\n**Problem:** Using f-strings with JSON examples causes \"Invalid format specifier\" errors.\n\n```python\n# ❌ THIS WILL FAIL - f-string sees { and } as format specifiers\nprompt = f\"\"\"\nGenerate JSON like this:\n{\n    \"patterns\": [\"\\\\d+\"],  # <-- Error: Invalid format specifier\n    \"data\": {\"key\": \"value\"}\n}\n\"\"\"\n\n# ✅ CORRECT - Escape braces with {{ and }}\nprompt = f\"\"\"\nGenerate JSON like this:\n{{\n    \"patterns\": [\"\\\\\\\\d+\"],\n    \"data\": {{\"key\": \"value\"}}\n}}\nDocument preview: {document_preview}  # <-- f-string substitution still works\n\"\"\"\n```\n\n### JSON Regex Escaping\n\n**Problem:** JSON requires double escaping for regex patterns.\n\n```python\n# ❌ WRONG - Single backslash breaks JSON parsing\nprompt = f\"\"\"Return this JSON:\n{{\n    \"patterns\": [\"\\d+\", \"\\w+\"]  # <-- JSON parsing error\n}}\"\"\"\n\n# ✅ CORRECT - Use double backslash for JSON\nprompt = f\"\"\"Return this JSON:\n{{\n    \"patterns\": [\"\\\\\\\\d+\", \"\\\\\\\\w+\"]  # <-- Proper JSON escaping\n}}\"\"\"\n\n# In the actual regex, this becomes \\d+ and \\w+ as expected\n```\n\n### Token Limits and Truncation\n\n**Problem:** LLM responses get truncated, causing invalid JSON.\n\n```python\n# ❌ RISKY - May truncate mid-JSON\nresponse = await generate_text(\n    prompt=prompt,\n    max_tokens=500  # <-- Too small for complex JSON\n)\n\n# ✅ SAFE - Ensure enough tokens for complete response\nresponse = await generate_text(\n    prompt=prompt,\n    max_tokens=3000,  # <-- Generous limit\n    temperature=0.3   # <-- Lower temp for consistent structure\n)\n\n# Always check for truncation\nif response and response.endswith('...'):\n    logger.warning(\"Response may be truncated\")\n```\n\n### Artifact Extraction Pattern\n\n**Problem:** Agent responses are wrapped in artifact structure, not raw data.\n\n```python\n# ❌ WRONG - Treating response as direct data\nkeyword_response = await self.call_agent(\"keyword\", message)\npatterns = keyword_response[\"patterns\"]  # <-- KeyError!\n\n# ✅ CORRECT - Extract from artifact first\ndef _extract_from_artifact(self, response):\n    \"\"\"Helper to extract data from artifact structure.\"\"\"\n    if isinstance(response, dict):\n        if \"parts\" in response:\n            for part in response[\"parts\"]:\n                if part.get(\"kind\") == \"data\":\n                    return part.get(\"data\")\n                elif part.get(\"kind\") == \"text\":\n                    return part.get(\"text\")\n    return response\n\n# Use the helper\nkeyword_response = await self.call_agent(\"keyword\", message)\ndata = self._extract_from_artifact(keyword_response)\npatterns = data.get(\"patterns\", [])\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Clean JSON Extraction from Code Blocks\n\n**Problem:** LLM often returns JSON wrapped in markdown code blocks.\n\n```python\n# LLM might return:\n# ```json\n# {\"key\": \"value\"}\n# ```\n\n# ✅ Handle code block extraction\nif llm_response and '```json' in llm_response:\n    start = llm_response.find('```json') + 7\n    end = llm_response.find('```', start)\n    if end > start:\n        cleaned_response = llm_response[start:end]\n    else:\n        cleaned_response = llm_response\nelse:\n    cleaned_response = llm_response\n\n# Then parse the cleaned JSON\ndata = json.loads(cleaned_response)\n```\n\n### No Fallback Patterns\n\n**Problem:** Hardcoded fallback patterns mask LLM failures.\n\n```python\n# ❌ WRONG - Hides LLM problems\ntry:\n    patterns = extract_patterns_from_llm(response)\nexcept:\n    patterns = [\"(?i)patient\", \"\\\\d+\"]  # <-- NO! This hides issues\n\n# ✅ CORRECT - Return empty on failure, log the error\ntry:\n    patterns = extract_patterns_from_llm(response)\nexcept Exception as e:\n    logger.error(f\"LLM pattern generation failed: {e}\")\n    patterns = []  # <-- Empty is honest, shows something went wrong\n```\n\n### Testing Without Real Orchestrator\n\n**Problem:** Direct agent calls don't trigger tool execution.\n\n```python\n# ❌ WRONG - Bypasses tools\nagent = SimpleOrchestratorAgent()\nresult = await agent.process_message(\"analyze this\")  # <-- Tools not invoked!\n\n# ✅ CORRECT - Call through execute_pipeline for orchestrators\nagent = SimpleOrchestratorAgent()\nresult = await agent.execute_pipeline(\"analyze this\")  # <-- Proper execution\n\n# OR override process_message to call execute_pipeline\nasync def process_message(self, message: str) -> str:\n    return await self.execute_pipeline(message)\n```",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}